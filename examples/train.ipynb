{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
      "Starting program on device [gpu(id=0)]\n",
      "SingleDataSystem loaded from: \n",
      " '/global/u2/r/ruiqig/deepmd-jax/data_example/water_test_data/1'\n",
      " with 1517 frames and 192 atoms per frame.\n",
      "Lattice vectors computed with 1 neighbor image condidates and max 1 images.\n",
      "Model statistics computed.\n",
      "Model initialized with 810146 parameters.\n",
      "Optimizer initialized. Training started.\n",
      "Iter       0 L 13.29553 LE 0.13914 LF 0.42035 Time 4.45s\n",
      "Iter    1000 L 6.73748 LE 0.05199 LF 0.21303 Time 6.42s\n",
      "Iter    2000 L 5.70486 LE 0.05509 LF 0.18037 Time 3.17s\n",
      "Iter    3000 L 5.27959 LE 0.07069 LF 0.16690 Time 3.17s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/global/homes/r/ruiqig/deepmd-jax/examples/train.ipynb Cell 1\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperl/global/homes/r/ruiqig/deepmd-jax/examples/train.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39mfor\u001b[39;00m iteration \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(total_steps):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperl/global/homes/r/ruiqig/deepmd-jax/examples/train.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=97'>98</a>\u001b[0m     batch, _ \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39mget_batch(batch_size)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bperl/global/homes/r/ruiqig/deepmd-jax/examples/train.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=98'>99</a>\u001b[0m     variables, opt_state, state_args \u001b[39m=\u001b[39m train_step(batch, variables, opt_state, state_args, static_args)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bperl/global/homes/r/ruiqig/deepmd-jax/examples/train.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=99'>100</a>\u001b[0m     \u001b[39mif\u001b[39;00m iteration \u001b[39m%\u001b[39m print_every \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bperl/global/homes/r/ruiqig/deepmd-jax/examples/train.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=100'>101</a>\u001b[0m         \u001b[39mif\u001b[39;00m use_val_data:\n",
      "File \u001b[0;32m~/.conda/envs/deepmd-jax/lib/python3.9/site-packages/flax/core/frozen_dict.py:107\u001b[0m, in \u001b[0;36mFrozenDict.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    105\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFrozenDict(\u001b[39m\u001b[39m{\u001b[39;00mpretty_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dict)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__hash__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    108\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hash \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax import jit, random, tree_util\n",
    "import jax, optax\n",
    "import flax.linen as nn\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from deepmd_jax.data import SingleDataSystem\n",
    "from deepmd_jax.model import DPModel\n",
    "import pickle\n",
    "from time import time\n",
    "print('Starting program on device', jax.devices())\n",
    "TIC = time()\n",
    "\n",
    "# Default to use 32 bit, you can change to 16 (for mixed 16/32bit) or 64 bit (not recommended)\n",
    "precision      = '32' # '16' '32' '64'\n",
    "if precision == '32':\n",
    "    jax.config.update('jax_default_matmul_precision', 'float32')\n",
    "if precision == '64':\n",
    "    jax.config.update('jax_enable_x64', True)\n",
    "\n",
    "# DP config parameters\n",
    "save_name      = 'model_polaron.pkl' # model save name\n",
    "train_data     = SingleDataSystem(['../data_example/water_test_data/1'], ['coord', 'box', 'force', 'energy'])\n",
    "# train_data     = SingleDataSystem(['../data_example/polaron_data'], ['coord', 'box', 'force', 'energy'])\n",
    "use_val_data   = False # if False, comment next line\n",
    "# val_data       = SingleDataSystem(['data_example/polaron_data'], ['coord', 'box', 'force', 'energy'])\n",
    "rcut           = 6.0\n",
    "embed_widths   = [24, 48, 96]\n",
    "fit_widths     = [240, 240, 240]\n",
    "axis_neuron    = 12\n",
    "batch_size     = 1\n",
    "val_batch_size = 8\n",
    "lr             = 0.002 \n",
    "s_pref_e       = 0.02\n",
    "l_pref_e       = 1\n",
    "s_pref_f       = 1000\n",
    "l_pref_f       = 100\n",
    "total_steps    = 400000\n",
    "decay_steps    = 4000\n",
    "decay_rate     = 0.95\n",
    "print_every    = 1000\n",
    "\n",
    "# parameters you usually don't need to change\n",
    "RANDOM_SEED    = np.random.randint(1000)\n",
    "beta2          = 0.99\n",
    "l_smoothing    = 20\n",
    "getstat_bs     = 64\n",
    "\n",
    "train_data.compute_lattice_candidate(rcut)\n",
    "if use_val_data:\n",
    "    val_data.compute_lattice_candidate(rcut)\n",
    "model = DPModel({'embed_widths':embed_widths,\n",
    "                 'fit_widths':fit_widths,\n",
    "                 'axis_neuron':axis_neuron,\n",
    "                 'Ebias':train_data.compute_Ebias()})\n",
    "batch, lattice_args = train_data.get_batch(getstat_bs)\n",
    "static_args = nn.FrozenDict({'lattice': lattice_args,\n",
    "                            'rcut':rcut,\n",
    "                            'type_index':tuple(train_data.type_index),\n",
    "                            'ntype_index':tuple(lattice_args['lattice_max']*train_data.type_index)})\n",
    "model.get_stats(batch['coord'], batch['box'], static_args)\n",
    "print('Model statistics computed.')\n",
    "variables = model.init(random.PRNGKey(RANDOM_SEED), batch['coord'][0], batch['box'][0], static_args)\n",
    "print('Model initialized with', sum(i.size for i in tree_util.tree_flatten(variables)[0]), 'parameters.')\n",
    "lr_scheduler = optax.exponential_decay(init_value=lr, transition_steps=decay_steps,\n",
    "                    decay_rate=decay_rate, transition_begin=0, staircase=True)\n",
    "optimizer = optax.adam(learning_rate=lr_scheduler, b2=beta2)\n",
    "opt_state = optimizer.init(variables)\n",
    "loss, loss_and_grad = model.get_loss_ef_fn()\n",
    "print('Optimizer initialized. Training started.')\n",
    "\n",
    "\n",
    "state_args = {'le_avg':0., 'lf_avg':0., 'loss_avg':0., 'iteration':0}\n",
    "def train_step(batch, variables, opt_state, state_args, static_args):\n",
    "    r = lr_scheduler(state_args['iteration']) / lr\n",
    "    pref = {'e': s_pref_e*r + l_pref_e*(1-r), 'f': s_pref_f*r + l_pref_f*(1-r)}\n",
    "    (loss_total, (loss_e, loss_f)), grads = loss_and_grad(variables, batch, pref, static_args)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    variables = optax.apply_updates(variables, updates)\n",
    "    state_args['loss_avg'] = state_args['loss_avg'] * (1-1/l_smoothing) + loss_total\n",
    "    state_args['le_avg'] = state_args['le_avg'] * (1-1/l_smoothing) + loss_e\n",
    "    state_args['lf_avg'] = state_args['lf_avg'] * (1-1/l_smoothing) + loss_f\n",
    "    state_args['iteration'] += 1\n",
    "    return variables, opt_state, state_args\n",
    "train_step = jit(train_step, static_argnums=(4,))\n",
    "\n",
    "def val_step(batch, variables, static_args):\n",
    "    pref = {'e': 1, 'f': 1}\n",
    "    _, (loss_e, loss_f) = loss(variables, batch, pref, static_args)\n",
    "    return loss_e, loss_f\n",
    "if use_val_data:\n",
    "    val_step = jit(val_step, static_argnums=(2,))\n",
    "\n",
    "tic = time()\n",
    "for iteration in range(total_steps):\n",
    "    batch, _ = train_data.get_batch(batch_size)\n",
    "    variables, opt_state, state_args = train_step(batch, variables, opt_state, state_args, static_args)\n",
    "    if iteration % print_every == 0:\n",
    "        if use_val_data:\n",
    "            val_batch, _ = val_data.get_batch(val_batch_size)\n",
    "            loss_val_e, loss_val_f = val_step(val_batch, variables, static_args)\n",
    "        beta = l_smoothing * (1 - (1/l_smoothing)**(iteration+1))\n",
    "        print('Iter %7d' % iteration +\n",
    "              ' L %7.5f' % (state_args['loss_avg']/beta)**0.5 + \n",
    "              ' LE %7.5f' % ((state_args['le_avg']/beta)**0.5/train_data.natoms) +\n",
    "              ' LF %7.5f' % (state_args['lf_avg']/beta)**0.5 + \n",
    "              (' LEval %7.5f' % ((loss_val_e)**0.5/val_data.natoms) if use_val_data else '') +\n",
    "              (' LFval %7.5f' % (loss_val_f)**0.5 if use_val_data else '') +\n",
    "              ' Time %.2fs' % (time()-tic))\n",
    "        tic = time()\n",
    "\n",
    "with open(save_name, 'wb') as file:\n",
    "    pickle.dump({'model':model, 'variables':variables}, file)\n",
    "T = int(time() - TIC)\n",
    "print('Model saved to \\'%s\\'.' % save_name)\n",
    "print('Training finished in %dh %dm %ds.' % (T//3600,(T%3600)//60,T%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.lattice_cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.vmap(jnp.diag)(jax.vmap(jnp.diag)(np.ones((3,2,2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(False, dtype=bool)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data.data['box'] - jax.vmap(jnp.diag)(jax.vmap(jnp.diag)(train_data.data['box']))).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1, 0],\n",
       "       [3, 2, 1, 0],\n",
       "       [3, 2, 1, 0],\n",
       "       [3, 2, 1, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-np.arange(16).reshape(4,4)).argpartition(2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(3, 0), dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.lattice_cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.20520687, dtype=float32), Array(0.18277217, dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 4\n",
    "e, debug = model.apply(variables, train_data.data['coord'][i], train_data.data['box'][i], static_args)\n",
    "(r_NM, embed_nmC, R_4NM, G_N4C, Feat_NX, fit_n1) = debug\n",
    "np.std(G_N4C), np.std(Feat_NX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.212533, dtype=float32), Array(0.16364186, dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 4\n",
    "e, debug = model.apply(variables, train_data.data['coord'][i], train_data.data['box'][i], static_args)\n",
    "(r_NM, embed_nmC, R_4NM, G_N4C, Feat_NX, fit_n1) = debug\n",
    "np.std(G_N4C), np.std(Feat_NX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
